#version 460
#extension GL_GOOGLE_include_directive              : enable
#extension GL_EXT_ray_tracing                       : enable
#extension GL_EXT_ray_query                         : enable
#extension GL_EXT_shader_explicit_arithmetic_types  : enable
#extension GL_EXT_nonuniform_qualifier              : enable
#extension GL_EXT_control_flow_attributes           : enable
#extension GL_KHR_shader_subgroup_ballot            : enable
#extension GL_KHR_shader_subgroup_arithmetic        : enable

#include "common/camera.glsl"
#include "common/random.glsl"
#include "common/normal_encode.glsl"
#include "common/raytrace.glsl"
#include "common/bsdf_diffuse.glsl"
#include "common/grid.glsl"
#include "common/colors_yuv.glsl"

uint rng_state;
vec2 moments;
vec3 irr_samples;

#include "config.h"
#include "layout.glsl"
#include "shading.glsl"
#include "light_cache.glsl"
#include "mc.glsl"
#include "raytrace.glsl"

void main() {
    const ivec2 pixel = ivec2(gl_GlobalInvocationID);
    const ivec2 resolution = ivec2(imageSize(img_irradiance));

    rng_state = 9771967 * (pixel.y + resolution.y * pixel.x) + params.frame * resolution.x * resolution.y;
    moments = vec2(0);
    irr_samples = vec3(0); // store sample count in `a` for accum node

    ShadingMaterial first_mat;
    {
        const vec3 first_wi = get_camera_ray_dir(pixel /*+ pixel_offset_blackman_harris(XorShift32Vec2(rng_state))*/, resolution, params.cam_u.xyz, params.cam_w.xyz, FOV_TAN_ALPHA_HALF);
        // Find first surface
        IntersectionInfo info;
        trace_ray(params.cam_x.xyz, first_wi, info);
        if (info.t > 0) {
            get_shading_material(info, params.cam_x.xyz, first_wi, first_mat);
        } else {
            get_sky(params.cam_x.xyz, first_wi, first_mat);
        }
    }

    const uint SPP = MAX_SPP;
    {
        // Store motion vector
        const vec3 old_dir = first_mat.pos - params.prev_cam_x.xyz;
        // Should compensate pixel filter..
        const vec2 old_pixel = get_camera_pixel(old_dir, resolution, params.prev_cam_u.xyz, params.prev_cam_w.xyz, FOV_TAN_ALPHA_HALF);
        if (all(lessThan(pixel, resolution))) {
            imageStore(img_mv, pixel, vec4(old_pixel - pixel, 0, 0));
        }

        // if (ADAPTIVE_SAMPLING == 1) {
        //     const ivec2 iold = ivec2(round(old_pixel));
        //     const vec2 old_gbuf = texelFetch(img_prev_gbuf, iold, 0).rg;
        //     const vec3 old_n = geo_decode_normal_float(old_gbuf.r);
        //     const float new_z = distance(params.cam_x.xyz, first_mat.pos);
        //     const bool reuse = all(lessThan(iold, resolution)) && dot(old_n, first_mat.normal) > .8 && abs(old_gbuf.g - new_z) / max(old_gbuf.g, new_z) < 0.1;
            
        //     const float mean = mean_variance[0];
        //     const float var = reuse ? texelFetch(img_prev_filtered, iold, 0).a : mean;
        //     float normalized_variance = subgroupMax(var) / mean;
        //     SPP = uint(ceil(min(normalized_variance, 1) * (MAX_SPP - 1)));
        // } else {
        //     SPP = MAX_SPP;
        // }
    }

    {
        // Evaluate direct light
        if (MAX_PATH_LENGTH > 0) {
            irr_samples = first_mat.emission;
            float l = yuv_luminance(irr_samples);
            moments += vec2(l, l * l);

            // const float mc_f = yuv_luminance(first_mat.emission);
            // MCState mc_state = mc_state_new();
            // mc_state_add_sample(mc_state, first_mat.pos + vec3(1), mc_f, first_mat.pos);
            // mc_state_save_adaptive(mc_state, first_mat.pos, first_mat.normal, rng_state);
        }
    }

    {
        // Evaluate indirect light (if light can be transported and the material is not emissive)
        if (any(greaterThanEqual(first_mat.albedo.rgb, vec3(1e-7))) && !any(greaterThanEqual(first_mat.emission, vec3(1e-7))))
        for (int s = 0; s < SPP; s++) {
            vec3 wi = normalize(first_mat.pos - params.cam_x.xyz);
            ShadingMaterial current_mat = first_mat;
            vec3 current_albedo = vec3(1);
            vec3 f = vec3(0);
            float p = 1.0;

            for (int segment = 1; segment < MAX_PATH_LENGTH; segment++) {
                vec3 wo;
                float wodotn;
                float wo_p = 0;
                MCState mc_state;
                // SAMPLE NEXT OUTGOING DIRECTION
                float score_sum = 0;
                {
                    float scores[MC_SAMPLES];
                    vec4 vmfs[MC_SAMPLES];
                    {
                        [[unroll]]
                        for (int i = 0; i < MC_SAMPLES; i++) {
                            MCState state;
                            if (XorShift32(rng_state) < MC_SAMPLES_ADAPTIVE_PROB) {
                                mc_adaptive_load(state, current_mat.pos, current_mat.normal);
                            } else {
                                mc_static_load(state, current_mat.pos, current_mat.normal);
                            }

                            scores[i] = state.sum_w;
                            score_sum += scores[i];
                            vmfs[i] = mc_state_get_vmf(state, current_mat.pos);
                            if (XorShift32(rng_state) < scores[i] / score_sum) {
                                // we use here that comparison with NaN is false, that happens if candidate_score == 0 and sum == 0; 
                                mc_state = state;
                                wo = vmf_sample(vmfs[i].xyz, vmfs[i].w, XorShift32Vec2(rng_state));
                            }
                        }
                    }

                    if (XorShift32(rng_state) < bsdf_p() || score_sum == 0) {
                        // BSDF Sampling
                        wo = bsdf_diffuse_sample(current_mat.normal, XorShift32Vec2(rng_state));
                        mc_state = mc_state_new(current_mat.pos, current_mat.normal);
                    } // else {VMF Sampling // wo = set above }
                    wodotn = dot(wo, current_mat.normal);


                    // Multiple importance sampling
                    [[unroll]]
                    for (int i = 0; i < MC_SAMPLES; i++) {
                        // score_sum > 0 ? results in black artifacts
                        wo_p += (scores[i] > 0 ? scores[i] * (vmf_pdf(vmfs[i].w, dot(wo, vmfs[i].xyz))) / score_sum : 0);
                    }
                    wo_p = (score_sum > 0 ? bsdf_p() : 1.0) * bsdf_diffuse_pdf(wodotn) + (1 - bsdf_p()) * wo_p;

                }

                // ray is below geometric surface
                if (dot(wo, current_mat.geo_normal) <= 1e-6 || wodotn <= 1e-3)
                    break;

                // TRACE RAY TO NEXT SURFACE
                ShadingMaterial next_mat;
                {
                    IntersectionInfo info;
                    // Pull back the ray such that it cannot excape through corners (and to prevent self collision)
                    trace_ray(current_mat.pos - wi * 1e-3, wo, info);
                    if (info.t > 0) {
                        get_shading_material(info, current_mat.pos, wo, next_mat);
                    } else {
                        get_sky(current_mat.pos, wo, next_mat);
                    }
                }

                // EVALUATE BSDF
                current_albedo *= bsdf_diffuse_eval(current_mat.albedo.rgb) * wodotn;
                const vec3 next_lc = light_cache_get(next_mat.pos, next_mat.normal).rgb;

                if (USE_LIGHT_CACHE_TAIL == 1) {
                    const vec3 incident = segment < MAX_PATH_LENGTH - 1 || any(greaterThan(next_mat.emission, vec3(0))) ? next_mat.emission : next_lc;
                    f = current_albedo * incident;
                } else {
                    f = current_albedo * next_mat.emission;
                }
                p *= wo_p;

                // UPDATE MARKOV CHAIN and LIGHT_CACHE
                {
                    const vec3 incident = (any(greaterThan(next_mat.emission, vec3(0))) ? next_mat.emission : next_lc) * bsdf_diffuse_eval(current_mat.albedo.rgb) * wodotn / wo_p;
                    const float mc_f = yuv_luminance(incident);
                    if (!isinf(mc_f)) {
                        light_cache_update(current_mat.pos, current_mat.normal, incident);

                        mc_state_add_sample(mc_state, current_mat.pos, mc_f, next_mat.pos);
                        if (XorShift32(rng_state) < mc_f / ((score_sum) / (MC_SAMPLES))) {
                            mc_static_save(mc_state, current_mat.pos, current_mat.normal);
                            mc_adaptive_save(mc_state, current_mat.pos, current_mat.normal);
                        }
                    }
                }

                // PREPARE NEXT ITERATION
                {
                    // we stop if we won't transport any more light or if we found emissive material
                    if (all(lessThan(current_albedo, vec3(1e-7))) || any(greaterThan(f, vec3(1e-7))))
                    break;

                    wi = wo;
                    current_mat = next_mat;
                }
            }

            // Albdeo demodulation
            const vec3 contrib = f / p;
            if(!any(isinf(contrib)) && !any(isnan(contrib))) {
                irr_samples += contrib * (1.0 / SPP);
                float l = yuv_luminance(contrib);
                moments += vec2(l, l * l) * (1.0 / SPP);
            }
        }
    }

    // irr_samples = filtered;
    // if (all(lessThan(pixel, resolution))) {
    //     imageStore(img_debug, pixel, vec4(SPP) / MAX_SPP);
    // }

    // show light cache
    // irr_samples = vec3(light_cache_get(first_mat.pos, first_mat.normal, rng_state));
    
    // MCState mc_state = mc_state_new();
    // mc_state_load_adaptive_resample(mc_state, first_mat.pos, first_mat.normal, rng_state);
    // irr_samples = vec3(mc_state.level / float(MC_LEVELS));

    // MCState mc_state = mc_state_new();
    // mc_state_load_adaptive_resample(mc_state, first_mat.pos, first_mat.normal, rng_state);
    // irr_samples = vec3(mc_state.sum_w);

    if (all(lessThan(pixel, resolution))) {
        // Required for albedo demodulation
        // Since irradiance is blurred set it to 1 and keep detail in albedo texture
        vec3 albedo = any(greaterThan(first_mat.emission, vec3(0))) ? first_mat.emission : first_mat.albedo.rgb;
        imageStore(img_albedo, pixel, vec4(albedo, 1));
        albedo = all(greaterThan(albedo.rgb, vec3(1e-7))) ? albedo : vec3(1);

        irr_samples /= albedo;
        const float alb_l = yuv_luminance(albedo);
        moments /= vec2(alb_l, alb_l * alb_l);

        // Store irradiance
        imageStore(img_irradiance, pixel, vec4(irr_samples, 0));

        // Store GBuffer
        gbuffer[gbuffer_index(pixel, resolution)].enc_normal = geo_encode_normal(first_mat.normal);
        gbuffer[gbuffer_index(pixel, resolution)].linear_z = distance(params.cam_x.xyz, first_mat.pos);

        imageStore(img_moments, pixel, vec4(moments, 0, 0));
    }

    // vec4 l = light_cache_get(first_mat.pos, first_mat.normal, rng_state);
    // imageStore(img_albedo, pixel, l);

    // {
    //     const ivec3 grid_idx = grid_idx_closest(first_mat.pos, GRID_WIDTH);
    //     uint buf_idx = hash_grid(grid_idx, BUFFER_SIZE);
    //     imageStore(img_albedo, pixel, XorShift32Vec4(buf_idx));
    // }

    // {
    //     MCState mc_state = mc_state_load_adaptive(first_mat.pos, rng_state);
    //     const vec4 vmf = mc_state_get_vmf(mc_state, first_mat.pos);
    //     imageStore(img_albedo, pixel, vec4(mc_state.f));
    // }
}
