#version 460
#extension GL_GOOGLE_include_directive              : enable
#extension GL_EXT_ray_tracing                       : enable
#extension GL_EXT_ray_query                         : enable
#extension GL_EXT_shader_explicit_arithmetic_types  : enable
#extension GL_EXT_nonuniform_qualifier              : enable
#extension GL_EXT_control_flow_attributes           : enable
#extension GL_KHR_shader_subgroup_ballot            : enable
#extension GL_KHR_shader_subgroup_arithmetic        : enable

#include "common/camera.glsl"
#include "common/random.glsl"
#include "common/normal_encode.glsl"
#include "common/raytrace.glsl"
#include "common/bsdf_diffuse.glsl"
#include "common/grid.glsl"
#include "common/colors_yuv.glsl"

uint rng_state;
vec2 moments;
vec3 irr_samples;

#include "config.h"
#include "layout.glsl"
#include "shading.glsl"
#include "light_cache.glsl"
#include "mc.glsl"
#include "raytrace.glsl"

void main() {
    const ivec2 pixel = ivec2(gl_GlobalInvocationID);
    const ivec2 resolution = ivec2(imageSize(img_irradiance));

    rng_state = 9771967 * (pixel.y + resolution.y * pixel.x) + params.frame * resolution.x * resolution.y;
    moments = f16vec2(0);
    irr_samples = f16vec3(0); // store sample count in `a` for accum node
    f16vec3 camera_throughput = f16vec3(1);

    Hit first_hit;
    {
        first_hit.wi = get_camera_ray_dir(pixel /*+ pixel_offset_blackman_harris(XorShift32Vec2(rng_state))*/, resolution, params.cam_u.xyz, params.cam_w.xyz, FOV_TAN_ALPHA_HALF);
        first_hit.pos = params.cam_x.xyz;
        f16vec3 incident = f16vec3(0);
        trace_ray(camera_throughput, incident, first_hit);
        irr_samples += incident;
    }

    const uint SPP = MAX_SPP;
    {
        // Store motion vector
        const vec3 old_dir = first_hit.pos - params.prev_cam_x.xyz;
        // Should compensate pixel filter..
        const vec2 old_pixel = get_camera_pixel(old_dir, resolution, params.prev_cam_u.xyz, params.prev_cam_w.xyz, FOV_TAN_ALPHA_HALF);
        if (all(lessThan(pixel, resolution))) {
            imageStore(img_mv, pixel, vec4(old_pixel - pixel, 0, 0));
            imageStore(img_albedo, pixel, vec4(first_hit.albedo, 1));

            // Store GBuffer
            gbuffer[gbuffer_index(pixel, resolution)].enc_normal = geo_encode_normal(first_hit.normal);
            gbuffer[gbuffer_index(pixel, resolution)].linear_z = distance(params.cam_x.xyz, first_hit.pos);
        }

        // if (ADAPTIVE_SAMPLING == 1) {
        //     const ivec2 iold = ivec2(round(old_pixel));
        //     const vec2 old_gbuf = texelFetch(img_prev_gbuf, iold, 0).rg;
        //     const vec3 old_n = geo_decode_normal_float(old_gbuf.r);
        //     const float new_z = distance(params.cam_x.xyz, first_hit.pos);
        //     const bool reuse = all(lessThan(iold, resolution)) && dot(old_n, first_hit.normal) > .8 && abs(old_gbuf.g - new_z) / max(old_gbuf.g, new_z) < 0.1;
            
        //     const float mean = mean_variance[0];
        //     const float var = reuse ? texelFetch(img_prev_filtered, iold, 0).a : mean;
        //     float normalized_variance = subgroupMax(var) / mean;
        //     SPP = uint(ceil(min(normalized_variance, 1) * (MAX_SPP - 1)));
        // } else {
        //     SPP = MAX_SPP;
        // }
    }

    // {
    //     // Evaluate direct light
    //     if (MAX_PATH_LENGTH > 0) {
    //         irr_samples = first_mat.emission;
    //         float l = yuv_luminance(irr_samples);
    //         moments += vec2(l, l * l);

    //         // const float mc_f = yuv_luminance(first_mat.emission);
    //         // MCState mc_state = mc_state_new();
    //         // mc_state_add_sample(mc_state, first_mat.pos + vec3(1), mc_f, first_mat.pos);
    //         // mc_state_save_adaptive(mc_state, first_mat.pos, first_mat.normal, rng_state);
    //     }
    // }

    {
        // Evaluate indirect light (if light can be transported and the material is not emissive)
        if (any(greaterThanEqual(first_hit.albedo, f16vec3(1e-7))) && !any(greaterThanEqual(irr_samples, vec3(1e-7))))
        for (int s = 0; s < SPP; s++) {
            Hit current_hit = first_hit;
            vec3 current_throughput = camera_throughput;
            vec3 f = vec3(0);
            float p = 1.0;

            for (int segment = 1; segment < MAX_PATH_LENGTH; segment++) {
                vec3 wo;
                float wodotn;
                float wo_p = 0;
                MCState mc_state;
                // SAMPLE NEXT OUTGOING DIRECTION
                float score_sum = 0;
                {
                    float scores[MC_SAMPLES];
                    vec4 vmfs[MC_SAMPLES];
                    {
                        [[unroll]]
                        for (int i = 0; i < MC_SAMPLES; i++) {
                            MCState state;
                            if (XorShift32(rng_state) < MC_SAMPLES_ADAPTIVE_PROB) {
                                mc_adaptive_load(state, current_hit.pos, current_hit.normal);
                            } else {
                                mc_static_load(state, current_hit.pos, current_hit.normal);
                            }

                            scores[i] = state.sum_w;
                            score_sum += scores[i];
                            vmfs[i] = mc_state_get_vmf(state, current_hit.pos);
                            if (XorShift32(rng_state) < scores[i] / score_sum) {
                                // we use here that comparison with NaN is false, that happens if candidate_score == 0 and sum == 0; 
                                mc_state = state;
                                wo = vmf_sample(vmfs[i].xyz, vmfs[i].w, XorShift32Vec2(rng_state));
                            }
                        }
                    }

                    if (XorShift32(rng_state) < bsdf_p() || score_sum == 0) {
                        // BSDF Sampling
                        wo = bsdf_diffuse_sample(current_hit.normal, XorShift32Vec2(rng_state));
                        mc_state = mc_state_new(current_hit.pos, current_hit.normal);
                    } // else {VMF Sampling // wo = set above }
                    wodotn = dot(wo, current_hit.normal);


                    // Multiple importance sampling
                    [[unroll]]
                    for (int i = 0; i < MC_SAMPLES; i++) {
                        // score_sum > 0 ? results in black artifacts
                        wo_p += (scores[i] > 0 ? scores[i] * (vmf_pdf(vmfs[i].w, dot(wo, vmfs[i].xyz))) / score_sum : 0);
                    }
                    wo_p = (score_sum > 0 ? bsdf_p() : 1.0) * bsdf_diffuse_pdf(wodotn) + (1 - bsdf_p()) * wo_p;

                }

                // ray is below geometric surface
                if (dot(wo, geo_decode_normal(current_hit.enc_geonormal)) <= 1e-3 || wodotn <= 1e-3)
                    break;

                // TRACE RAY TO NEXT SURFACE
                Hit next_hit;
                next_hit.wi = wo;
                // Pull back the ray such that it cannot excape through corners (and to prevent self collision)
                next_hit.pos = current_hit.pos - current_hit.wi * 1e-3;
                f16vec3 incident = f16vec3(0);
                f16vec3 throughput = f16vec3(1);
                trace_ray(throughput, incident, next_hit);


                // EVALUATE BSDF
                current_throughput *= f16vec3(bsdf_diffuse_eval(current_hit.albedo) * wodotn);
                const f16vec3 next_lc = light_cache_get(next_hit.pos, next_hit.normal).rgb;

                if (USE_LIGHT_CACHE_TAIL == 1) {
                    const f16vec3 lc_incident = segment < MAX_PATH_LENGTH - 1 || any(greaterThan(incident, f16vec3(0))) ? incident : next_lc;
                    f = current_throughput * lc_incident;
                } else {
                    f = current_throughput * incident;
                }
                p *= wo_p;
                current_throughput *= throughput;

                // UPDATE MARKOV CHAIN and LIGHT_CACHE
                {
                    const vec3 lc_incident = (any(greaterThan(incident, f16vec3(0))) ? incident : throughput * next_lc) * bsdf_diffuse_eval(current_hit.albedo) * wodotn / wo_p;
                    const float mc_f = yuv_luminance(lc_incident);
                    if (!isinf(mc_f)) {
                        light_cache_update(current_hit.pos, current_hit.normal, lc_incident);

                        mc_state_add_sample(mc_state, current_hit.pos, mc_f, next_hit.pos);
                        if (XorShift32(rng_state) < mc_f / ((score_sum) / (MC_SAMPLES))) {
                            mc_static_save(mc_state, current_hit.pos, current_hit.normal);
                            mc_adaptive_save(mc_state, current_hit.pos, current_hit.normal);
                        }
                    }
                }

                // PREPARE NEXT ITERATION
                {
                    // we stop if we won't transport any more light or if we found emissive material
                    if (all(lessThan(current_throughput, vec3(1e-7))) || any(greaterThan(f, vec3(1e-7))))
                        break;
                    current_hit = next_hit;
                }
            }

            // Albdeo demodulation
            const vec3 contrib = f / p;
            if(!any(isinf(contrib)) && !any(isnan(contrib))) {
                irr_samples += contrib * (1.0 / SPP);
                float l = yuv_luminance(contrib);
                moments += vec2(l, l * l) * (1. / SPP);
            }
        }
    }
    // irr_samples = vec3(light_cache_get(first_hit.pos, first_hit.normal));

    if (all(lessThan(pixel, resolution))) {
        // Required for albedo demodulation
        // Since irradiance is blurred set it to 1 and keep detail in albedo texture

        if (all(greaterThan(first_hit.albedo, f16vec3(0)))) {
            irr_samples /= first_hit.albedo;
            const float alb_l = yuv_luminance(first_hit.albedo);
            moments /= vec2(alb_l, alb_l * alb_l);
        }

        imageStore(img_irradiance, pixel, vec4(irr_samples, 0));
        imageStore(img_moments, pixel, vec4(moments, 0, 0));
    }

    // irr_samples = filtered;
    // if (all(lessThan(pixel, resolution))) {
    //     imageStore(img_debug, pixel, vec4(SPP) / MAX_SPP);
    // }

    // show light cache
    
    
    // MCState mc_state = mc_state_new();
    // mc_state_load_adaptive_resample(mc_state, first_mat.pos, first_mat.normal, rng_state);
    // irr_samples = vec3(mc_state.level / float(MC_LEVELS));

    // MCState mc_state = mc_state_new();
    // mc_state_load_adaptive_resample(mc_state, first_mat.pos, first_mat.normal, rng_state);
    // irr_samples = vec3(mc_state.sum_w);

    // imageStore(img_debug, pixel, vec4(light_cache_get(first_mat.pos, first_mat.normal), 1));

    // {
    //     const ivec3 grid_idx = grid_idx_closest(first_mat.pos, GRID_WIDTH);
    //     uint buf_idx = hash_grid(grid_idx, BUFFER_SIZE);
    //     imageStore(img_albedo, pixel, XorShift32Vec4(buf_idx));
    // }

    // {
    //     MCState mc_state = mc_state_load_adaptive(first_mat.pos, rng_state);
    //     const vec4 vmf = mc_state_get_vmf(mc_state, first_mat.pos);
    //     imageStore(img_albedo, pixel, vec4(mc_state.f));
    // }
}
